{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b675f7f-e15a-4fcc-ac00-a9202855af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff268f-18f2-4005-8f69-f69c97feee6f",
   "metadata": {},
   "source": [
    "# Structured data\n",
    "\n",
    "During the previous classes, we discussed the use of linear regression model for structured data.\n",
    "In the simplest case, for one variable X and one target variable, we could, for example, assign the model in the form:\n",
    "\n",
    "life_satisfaction = $\\alpha_0$ + $\\alpha_1$ GDP_per_capita\n",
    "\n",
    "We call $\\alpha_0$ the intercept or bias term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ddfa6-d195-4eba-b828-aba9cfc27b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42) \n",
    "m = 100\n",
    "X = 2*np.random.rand(m,1) \n",
    "a_0, a_1 = 4, 3 \n",
    "y = a_0 + a_1 * X + np.random.randn(m,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07149527-e708-4fa3-8a8c-b96085525aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19ae95-46bf-4eec-9b1d-ea389774da9c",
   "metadata": {},
   "source": [
    "In general, the linear model is represented as:\n",
    "\n",
    "$\\hat{y} = \\alpha_0 + \\alpha_1 x_1 + \\alpha_2 x_2 + \\dots + \\alpha_n x_n$\n",
    "\n",
    "where $\\hat{y}$ is the prediction of our model (predicted value) for $n$ features with values $x_i$.\n",
    "\n",
    "In vectorized form, we can write:\n",
    "\n",
    "$\\hat{y} = \\vec{\\alpha}^{T} \\vec{x}$\n",
    "\n",
    "In this form, it is evident why a column of ones is added to this model - they correspond to the values $x_0$ for $\\alpha_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd68c4-b0ed-40fe-8688-c9ee9a966c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ones \n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "X_b = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779e8d9-78c1-4493-8187-147b6378468b",
   "metadata": {},
   "source": [
    "We said that in this model, we can find a cost function.\n",
    "\n",
    "$MSE(\\vec{x}, \\hat{y}) = \\sum_{i=1}^{m} \\left( \\vec{\\alpha}^{T} \\vec{x}^{(i)} - y^{(i)} \\right)^{2}$\n",
    "\n",
    "Actually, we can have $MSE(\\vec{x}, \\hat{y}) = MSE(\\vec{\\alpha})$.\n",
    "\n",
    "Analytical solution\n",
    "$\\vec{\\alpha} = (X^{T}X)^{-1} X^T y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5eb26-0ba9-4974-aa9f-40e03b696219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "alpha_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490b52f-11e6-4239-8577-916539f2fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_best, np.array([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49892cc-616c-49e4-98eb-1096730a1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = add_dummy_feature(X_new)\n",
    "y_predict = X_new_b @ alpha_best\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_new, y_predict, \"r-\", label=\"prediction\")\n",
    "plt.plot(X,y, \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d1315-c864-41ba-a5ec-22e3f54d6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X,y) \n",
    "\n",
    "print(f\"a_0={lin_reg.intercept_[0]}, a_1 = {lin_reg.coef_[0][0]}\")\n",
    "\n",
    "print(\"prediction\", lin_reg.predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfe1a7-4adc-445b-ad89-7c5d980f8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression w scikit learn oparta jest o metodę lstsq \n",
    "alpha_best_svd, _, _, _ = np.linalg.lstsq(X_b, y, rcond=1e-6)\n",
    "alpha_best_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b9e29-0299-4330-824f-5cbaac17c996",
   "metadata": {},
   "source": [
    "Remember about variable standardization (to represent them on the same scale).\n",
    "\n",
    "## Batch Gradient Descent\n",
    "For implementation, we need to calculate partial derivatives for the cost function with respect to each parameter $\\alpha_i$.\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\alpha_j}MSE(\\vec{x}, \\hat{y}) = 2 \\sum_{i=1}^{m} \\left( \\vec{\\alpha}^{T} \\vec{x}^{(i)} - y^{(i)} \\right) x_j^{(i)}$\n",
    "\n",
    "Computers have the property of matrix multiplication, which allows us to calculate all derivatives in one computation. \n",
    "The formula and algorithm calculating all derivatives \"at once\" use the entire set X, hence we call it **batch**.\n",
    "\n",
    "After calculating the gradient, we simply go \"in the opposite direction\".\n",
    "\n",
    "$ \\alpha_{next} = \\alpha - \\eta \\nabla_{\\alpha} MSE(\\alpha)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc984e3-4a98-4cd4-a805-c41a3eec365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./img/02_10.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e7bc9-9fd0-4a41-ad1b-1ac49b66994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "n_epochs = 1000\n",
    "m = len(X_b)\n",
    "np.random.seed(42) \n",
    "alpha = np.random.randn(2,1) # losowo wybieramy rozwiązanie\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    gradients = 2/m* X_b.T @ (X_b @ alpha - y)\n",
    "    #print(alpha)\n",
    "    alpha = alpha - eta*gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0652cbf-5bfe-46b6-b7ce-029f2a46fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfb9c4-9c62-44e1-ac1a-0aee1f1d1a28",
   "metadata": {},
   "source": [
    "verify for eta  0.02, 0.1, 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3889a-9077-4b6f-a672-1d97bfd83e74",
   "metadata": {},
   "source": [
    "Now a minor modification - we know that we don't want such a variable in the model - it has only one value. But how to verify which variables are these if you have 3 million columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666edfda-86b2-4e00-bff1-22a8cdc6b72a",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent\n",
    "\n",
    "One of the more serious problems with batch gradient is its dependence on using the entire data matrix (at each step). \n",
    "By utilizing statistical properties, we can observe how the convergence of the solution will proceed if we randomly draw a data sample each time and determine the gradient on it. \n",
    "Due to the fact that we store only a certain portion of the data in memory, this algorithm can be used for very large datasets. \n",
    "However, it is worth noting that the results obtained in this way are chaotic, which means that the cost function does not converge towards the minimum but rather jumps around, aiming towards the minimum in the sense of average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500a674-ab50-403c-8656-33381b2ff2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "m = len(X_b)\n",
    "\n",
    "\n",
    "def learning_schedule(t, t0=5, t1=50):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "np.random.seed(42)\n",
    "alpha = np.random.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index : random_index + 1]\n",
    "        yi = y[random_index : random_index + 1] \n",
    "        gradients = 2 * xi.T @ (xi @ alpha - yi)\n",
    "        eta = learning_schedule(epoch * m + iteration) \n",
    "        alpha = alpha - eta * gradients\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05959c79-d712-416e-941d-0930b3947f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b97411a-b0db-4abb-9848-c21bafcb47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-5, \n",
    "                       penalty=None, eta0=0.01, \n",
    "                       n_iter_no_change=100, random_state=42)\n",
    "\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27738ef3-c022-486c-be01-b19a755f7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c80b1-afbe-461a-a8ca-113507585133",
   "metadata": {},
   "source": [
    "## Perceptron and Python OOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2307838-7224-49d9-b19f-5c91b39b3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "randint(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5bf2e-58fd-4f64-b7eb-0775a0e0b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class Dice():\n",
    "    \"\"\"class descr\"\"\"\n",
    "        \n",
    "    def roll(self):\n",
    "        \"\"\"roll descr \"\"\"\n",
    "        # write a code to return random number from 1 to number of wals (def by user) \n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c32747-5087-48bc-b978-3e3986b817b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Dice()\n",
    "# roll a Dice 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc00121-12d9-4911-a52d-2e2712b8dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "choice([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5a523-3404-45be-899f-3286ccec1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class RandomWalk():\n",
    "    def __init__(self, num_points=5000):\n",
    "        self.num_points = num_points\n",
    "        self.x_values = [0]\n",
    "        self.y_values = [0]\n",
    "    \n",
    "    def fill_walk(self):\n",
    "        while len(self.x_values) < self.num_points:\n",
    "            x_direction = ...\n",
    "            x_distance = ...\n",
    "            x_step = x_direction*x_distance\n",
    "            \n",
    "            y_direction = ...\n",
    "            y_distance = ...\n",
    "            y_step = y_direction*y_distance\n",
    "            \n",
    "            if x_step == 0 and y_step == 0:\n",
    "                continue\n",
    "            \n",
    "            next_x = self.x_values[-1] + x_step\n",
    "            next_y = self.y_values[-1] + y_step\n",
    "            \n",
    "            self.x_values.append(next_x)\n",
    "            self.y_values.append(next_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fba9a9-0095-4a43-a24f-35ab87f1a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = RandomWalk(5)\n",
    "rw.fill_walk()\n",
    "rw.x_values, rw.y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc869b4-31f5-4c69-a7af-eb6f29535733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10_000 random walk points\n",
    "rw = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07ccae-a89a-4e23-bb0d-e632aa20cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "point_number = list(range(rw.num_points))\n",
    "plt.scatter(rw.x_values, rw.y_values, c=point_number, cmap=plt.cm.Blues,\n",
    "           edgecolor='none', s=15)\n",
    "plt.scatter(0,0,c='green', edgecolor='none', s=100)\n",
    "plt.scatter(rw.x_values[-1], rw.y_values[-1],c='red', edgecolor='none', s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465b477-2d65-4744-9de4-8271fd816106",
   "metadata": {},
   "source": [
    "### Sztuczne neurony - rys historyczny\n",
    "\n",
    "In 1943, W. McCulloch and W. Pitts presented the first concept of a simplified model of a nerve cell called the McCulloch-Pitts Neuron (MCP). [W.S. McCulloch, W. Pitts, A logical Calculus of the Ideas Immanent in Nervous Activity. \"The Bulletin of Mathematical Biophysics\" 1943 nr 5(4)](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf)\n",
    "\n",
    "Neurons are mutually connected nerve cells in the brain responsible for processing and transmitting chemical and electrical signals. Such a cell is described as a logical gate containing binary outputs. A large number of signals reach the dendrites, which are integrated in the cell body and (if the energy exceeds a certain threshold value) generate an output signal transmitted through the axon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d460a-9e56-4b47-bfbf-51b6e843172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./img/02_01.png', width=800) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b9d71-bb82-4692-872a-daee9a15a728",
   "metadata": {},
   "source": [
    "After several years, Frank Rosenblatt (based on the MCP) proposed the first concept of the perceptron learning rule. \n",
    "[F. Rosenblatt, The Perceptron, a Perceiving and Recognizing Automaton, Cornell Aeronautical Laboratory, 1957](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282aca55-e2fe-40cb-97b6-a937f5f784d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " Image(filename='./img/02_04.png', width=800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755cadce-efb0-4314-8cf6-19b5333f3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./img/02_02.png', width=800) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f2bf0-63b4-43b2-aef6-da765e8af2b2",
   "metadata": {},
   "source": [
    "> Ex\n",
    ">\n",
    "> Create numpy tables from data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce413aac-21b1-455c-9f76-0f81b15e66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "example_input = [1,.2,.1,.05,.2]\n",
    "example_weights = [.2,.12,.4,.6,.90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e07ccb-16c3-4578-a101-ce03ac2a6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = ...\n",
    "weights = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac76df2-fa73-4fb9-89c3-f7c6ffdb2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_wegiht = .2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d845e-c07b-47c8-9f7e-2aa7ae44109c",
   "metadata": {},
   "source": [
    "> Compute net input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae84098-59f2-41f2-aa9b-0015dc7f1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_level = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d906e-086d-461e-a82b-3acfbcea49c2",
   "metadata": {},
   "source": [
    "> assume threshold level at 0.5 and compute perceptron decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3ce56-c876-4c57-b3ca-385b58b2482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE \n",
    "\n",
    "\n",
    "print(perceptron_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db29035-20a3-4be8-8f88-c7d119feeee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42dd37-02b5-4fc5-8b58-857fea566c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10ef31-bd48-4db3-8e55-b1df2d82f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pdd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                  columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3cba64-193f-4cc5-a43c-e8af7b29aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:100,[0,2]].values\n",
    "y = df.iloc[0:100,4].values\n",
    "y = np.where(y == 0, -1, 1)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb20db3-77e7-496a-9553-357520545976",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1],color='red', marker='o',label='setosa')\n",
    "plt.scatter(X[50:100,0],X[50:100,1],color='blue', marker='x',label='versicolor')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('petal length (cm)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8fabe-1af1-4fd7-911d-dd81dfd2e8ed",
   "metadata": {},
   "source": [
    "```{python}\n",
    "childe = Perceptron()\n",
    "childe.fit()\n",
    "\n",
    "# eta parameter - how fast you will learn\n",
    "childe.eta\n",
    "\n",
    "# how many mistakes \n",
    "\n",
    "childe.errors_ \n",
    "\n",
    "# weights are solution\n",
    "childe.w_\n",
    "# in our case we have two weights\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef892f-fda1-4800-9ae3-3384bd3d5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, n_iter=10, eta=0.01):\n",
    "        self.n_iter = n_iter\n",
    "        self.eta = eta\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.w_ = np.zeros(1+X.shape[1])\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            pass\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13373d74-8756-43fe-aa6c-a0c3e621f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #self.w_ = np.zeros(1+X.shape[1])\n",
    "        self.w_ = [random.uniform(-1.0, 1.0) for _ in range(1+X.shape[1])] \n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X,y):\n",
    "                #print(xi, target)\n",
    "                update = self.eta*(target-self.predict(xi))\n",
    "                #print(update)\n",
    "                self.w_[1:] += update*xi\n",
    "                self.w_[0] += update\n",
    "                #print(self.w_)\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:])+self.w_[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X)>=0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e5e2e-b88e-4615-92f0-b2d2afa929ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like in scikitlearn\n",
    "ppn = Perceptron()\n",
    "ppn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e03702-62d7-42ad-a513-b2861e5e2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ppn.errors_)\n",
    "print(ppn.w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd833e52-fa19-45fb-873f-39d493059968",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn.predict(np.array([-3, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329266b-2d1f-4d04-8f4c-72396a676d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl', \"wb\") as picklefile:\n",
    "    pickle.dump(ppn, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00595af8-8859-47fa-ad92-1a8865396c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodatkowa funkcja\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X,y,classifier, resolution=0.02):\n",
    "    markers = ('s','x','o','^','v')\n",
    "    colors = ('red','blue','lightgreen','gray','cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    x1_min, x1_max = X[:,0].min() - 1, X[:,0].max()+1\n",
    "    x2_min, x2_max = X[:,1].min() -1, X[:,1].max()+1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl,0], y=X[y==cl,1], alpha=0.8, c=cmap(idx), marker=markers[idx], label=cl)\n",
    "\n",
    "# dla kwiatków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b38704-3faf-40ca-90a2-761732892434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X,y,classifier=ppn)\n",
    "plt.xlabel(\"dlugosc dzialki [cm]\")\n",
    "plt.ylabel(\"dlugosc platka [cm]\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331b30e-ebbd-44a7-ba1d-d342e05b67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./img/02_09.png', width=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4ccf5-26ad-4aba-b9e3-3b9661428ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE - Opisz czym różni się poniższy algorytm od Perceprtona ? \n",
    "class Adaline():\n",
    "    '''Klasyfikator  - ADAptacyjny LIniowy NEuron'''\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        import random\n",
    "        self.w_ = [random.uniform(-1.0, 1.0) for _ in range(1+X.shape[1])]\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(X)\n",
    "            errors = (y-output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f53b7b-598d-4f84-9f30-b340029d5a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = Adaline(n_iter=20, eta=0.01)\n",
    "\n",
    "ad.fit(X,y)\n",
    "\n",
    "print(ad.w_)\n",
    "\n",
    "plot_decision_regions(X,y,classifier=ad)\n",
    "# plt.xlabel(\"dlugosc dzialki [cm]\")\n",
    "# plt.ylabel(\"dlugosc platka [cm]\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe41175-fcb7-4f42-a8e8-9cd60ffe7d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.cost_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d6865-af7a-4ec0-9336-704aa0e683b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2 = Adaline(n_iter=100, eta=0.0001)\n",
    "\n",
    "ad2.fit(X,y)\n",
    "\n",
    "plot_decision_regions(X,y,classifier=ad2)\n",
    "# plt.xlabel(\"dlugosc dzialki [cm]\")\n",
    "# plt.ylabel(\"dlugosc platka [cm]\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb7d7f-f3a3-4c84-a6c2-041c573e4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ad2.w_)\n",
    "\n",
    "ad2.cost_[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4703b-94e6-46c6-ba77-02bb61f76bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app.py\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.w_ = [random.uniform(-1.0, 1.0) for _ in range(1+X.shape[1])] \n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X,y):\n",
    "                update = self.eta*(target-self.predict(xi))\n",
    "                self.w_[1:] += update*xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:])+self.w_[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X)>=0.0, 1, -1)\n",
    "\n",
    "# Create a flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Create an API end point\n",
    "@app.route('/predict_get', methods=['GET'])\n",
    "def get_prediction():\n",
    "    # sepal length\n",
    "    sepal_length = float(request.args.get('sl'))\n",
    "    petal_length = float(request.args.get('pl'))\n",
    "    \n",
    "    features = [sepal_length, petal_length]\n",
    "\n",
    "    # Load pickled model file\n",
    "    with open('model.pkl',\"rb\") as picklefile:\n",
    "        model = pickle.load(picklefile)\n",
    "        \n",
    "    # Predict the class using the model\n",
    "    predicted_class = int(model.predict(features))\n",
    "    \n",
    "    # Return a json object containing the features and prediction\n",
    "    return jsonify(features=features, predicted_class=predicted_class)\n",
    "\n",
    "@app.route('/predict_post', methods=['POST'])\n",
    "def post_predict():\n",
    "    data = request.get_json(force=True)\n",
    "    # sepal length\n",
    "    sepal_length = float(data.get('sl'))\n",
    "    petal_length = float(data.get('pl'))\n",
    "    \n",
    "    features = [sepal_length, petal_length]\n",
    "\n",
    "    # Load pickled model file\n",
    "    with open('model.pkl',\"rb\") as picklefile:\n",
    "        model = pickle.load(picklefile)\n",
    "        \n",
    "    # Predict the class using the model\n",
    "    predicted_class = int(model.predict(features))\n",
    "    output = dict(features=features, predicted_class=predicted_class)\n",
    "    # Return a json object containing the features and prediction\n",
    "    return jsonify(output)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529308e5-d489-45a8-8715-17c2fbf42754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://127.0.0.1:5000/predict_get?sl=6.3&pl=2.6\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55d7c9-3575-46f0-95d5-1de3b2012ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "json = {\"sl\":2.4, \"pl\":2.6}\n",
    "response = requests.post(\"http://127.0.0.1:5000/predict_post\", json=json)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7092e6-89b5-4e4e-9bd5-e2d2660f4901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
