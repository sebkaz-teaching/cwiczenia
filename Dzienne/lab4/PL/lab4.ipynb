{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bae4772-3891-499b-8a1d-5f04fea8c75c",
   "metadata": {},
   "source": [
    "### dane nieustruktyryzowane\n",
    "\n",
    "Dane nieustrukturyzowane to dane, które nie są w żaden sposób uporządkowane, takie jak:\n",
    "\n",
    "- obrazy,\n",
    "- teksty,\n",
    "- dźwięki,\n",
    "- wideo.\n",
    "  \n",
    "Niezależnie od typu, wszystko przetwarzamy w tensorach (macierzach wielowymiarowych). To może prowadzić do chęci wykorzystania modeli ML i sieci neuronowych do analizy danych nieustrukturyzowanych.\n",
    "\n",
    "![](data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581a868-9b7e-4fd5-b403-e479596539c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", palette=\"husl\")\n",
    "\n",
    "\n",
    "# 2-dim picture 28 x 28 pixel\n",
    "picture_2d = np.random.uniform(size=(28,28))\n",
    "picture_2d[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded90d39-d2ef-4763-a2bc-5b355968a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(picture_2d, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea7c23-43d9-4e8b-9bbe-1298a7d82e20",
   "metadata": {},
   "source": [
    "# pretrenowane modele klasyfikujące"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535ca42-8ddc-4f4f-b43a-2a886a8cd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'https://pytorch.tips/coffee'\n",
    "fpath = 'coffee.jpg'\n",
    "# pobierz na dysk\n",
    "urllib.request.urlretrieve(url, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e95603-c55d-43d1-8464-9c568f410467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # pillow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78cd6e-84b4-4328-ad4e-b7e272125a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('coffee.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c4360-2394-4408-9056-792242abe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision==0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f878df3-bc49-4d3e-b02a-2c5cbbe67a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319fe36b-d4a4-4c2b-b669-8d57771f445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "models.list_models()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822984fa-ab9b-4004-94be-59e4421225f9",
   "metadata": {},
   "source": [
    "Odrobinę zmienimy własności obrazka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc701e2a-4d40-4ecd-89b1-bd2384e6745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( \n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46484f4-77e6-4ce1-a39f-3cb0f4077d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496db06-e411-400b-a54a-60e3e557cbd3",
   "metadata": {},
   "source": [
    "Sprawdzmy rozmiary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb64298-13d9-4eaf-ad2c-400b0aba0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_tensor), img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2371cd6-3c56-407e-a243-e3ddd53b4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utworzenie batch size - dodatkowego wymiaru (na inne obrazki)\n",
    "batch = img_tensor.unsqueeze(0)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468c615-dc36-4d01-8c56-92901e23615c",
   "metadata": {},
   "source": [
    "Załadujmy gotowy model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249295c9-f97b-4758-bf13-f26f1b233b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21904a-63c1-4c82-88d9-b7dea3705f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1af0ef-98e0-4a91-9a7a-ff91b1910078",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.eval()\n",
    "predict = alexnet(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f1d52-10fa-4513-982f-aac0597fa856",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = torch.max(predict,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c6307-5c9d-4009-9b08-55ee620e2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578687b8-444c-4cd2-9f9c-346831eb2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pytorch.tips/imagenet-labels'\n",
    "fpath = 'imagenet_class_labels.txt'\n",
    "urllib.request.urlretrieve(url, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533a1a9-45d9-4ee6-911d-35661e41424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_class_labels.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75df9b6-3aa5-4ca0-89b0-4432a4f0ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da05280-41b1-4dea-a9e7-4d494b03d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(predict, dim=1)[0] *100\n",
    "prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37dae65-c8b9-46c2-8a2c-2131cbadc845",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[idx.item()], prob[idx.item()].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab216ce5-dd74-40f4-9ef1-3387b4f4591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7802d3-bb5d-4737-97d7-006bcc52f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0732d3-5ba1-464d-bcf6-d4dff3d0b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "out = resnet(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfed35a-4566-482b-aeed-cd2f7625c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(out,1)\n",
    "prob = torch.nn.functional.softmax(out, dim=1)[0] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5939960-a2f2-475b-bc0a-540972efe848",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[index.item()], prob[index.item()].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5174561-c09b-4e17-92f2-384e40118aab",
   "metadata": {},
   "source": [
    "### jeszcze obrazki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa30af4-3344-48bc-aca6-3e2e88d24c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60000 obrazow 28x28\n",
    "\n",
    "# Loading the Fashion-MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "# transformacja i normalizacja danych \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489ec43-f3a1-4107-a2ac-4c8bf4fa6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65584582-a6b9-4972-a2ee-2a67d3a4f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.randint(0, images.shape[0], size=25)\n",
    "images_rand = images[indexes]\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = images_rand[i]\n",
    "    plt.imshow(image[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa770f97-ec84-496e-86c3-ae3eeff920e0",
   "metadata": {},
   "source": [
    "Przykładowy model sieci nueronowej (bez konwolucji) - czy sądzisz, że to dobre rozwiązanie? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b1b31-2b82-415e-859a-204acf7be265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network architecture\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 10),\n",
    "                      nn.LogSoftmax(dim = 1)\n",
    "                     )\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.002)\n",
    "\n",
    "# Define the epochs\n",
    "epochs = 30\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    \n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model.forward(images)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  else:\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computation\n",
    "    with torch.no_grad():\n",
    "      # Set the model to evaluation mode\n",
    "      model.eval()\n",
    "      \n",
    "      # Validation pass\n",
    "      for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        log_ps = model(images)\n",
    "        test_loss += criterion(log_ps, labels)\n",
    "        \n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    \n",
    "    model.train()\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "    \n",
    "    print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Test loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d4960-1cdb-45f0-b9c2-55037e919ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label = \"Training loss\")\n",
    "plt.plot(test_losses, label = \"Validation loss\")\n",
    "plt.legend(frameon = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fabde8",
   "metadata": {},
   "source": [
    "![](wykres0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0a453",
   "metadata": {},
   "source": [
    "![](wykres1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc784a-5b49-4d80-8518-9da94999b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My model: \\n\\n\", model, \"\\n\")\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc4591-8cce-41a5-9d51-c58557263291",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c208b5-2755-4ee5-bf82-95e847861bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cba29e-6098-4dcb-8fd7-140cce30eae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42215e45-a8cf-4e67-b332-4cfdf5ffdcd6",
   "metadata": {},
   "source": [
    "A jakie inne sieci i warstwy możemy wykorzystać do analizy danych nieustrukturyzowanych? \n",
    "\n",
    "> Znajdź odpowiedź na to pytanie w dokumentacji biblioteki Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f73b8a-4cc0-400e-b46b-04d27c577ad7",
   "metadata": {},
   "source": [
    "## tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46dc96e-85de-4bea-b5d8-9f9cdb53e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train = df_train.drop(\"index\", axis=1)\n",
    "print(df_train.head())\n",
    "print(np.bincount(df_train[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099c2fb-30de-4c01-b924-2d3a3f09a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW model  - wektoryzator z sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(lowercase=True, max_features=10_000, stop_words=\"english\")\n",
    "\n",
    "cv.fit(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a156b7-80c4-41ba-bde2-4f684dda7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# słownik i nasze zmienne ..\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b1c4-9a7a-4653-acdb-4282b139843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.transform(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0adf4-ad47-4913-9b7e-b41b3093a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to dense matrix\n",
    "feat_vec = np.array(X_train[0].todense())[0]\n",
    "print(feat_vec.shape)\n",
    "np.bincount(feat_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9329ba9a-94bb-488c-a8b8-83c8b9de7af8",
   "metadata": {},
   "source": [
    "## Obiektowe podejście do modelowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a19144-7545-49cc-b534-919cbdbb8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# przykład danych ustrukturyzowanych\n",
    "df = pd.read_csv(\"students.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e031a3-10e7-4c3e-921a-400d786277b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dc43d-cfae-4cac-932e-6e514dc8c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa64470-983b-49e2-892b-3a0e6eb08e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ZAMIAST OD RAZU PRZETWARZAC !!! najpierw przygotuj kroki - pipeline\n",
    "\n",
    "numeric_features = ['math score','reading score','writing score']\n",
    "categorical_features = ['sex','race/ethnicity','parental level of education','lunch','test preparation course']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c8b94-0719-49cc-9c47-b7d0fbb55907",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0ec3a-bf9d-4760-b01b-7bea1734de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_trans\", numeric_transformer, numeric_features),\n",
    "    (\"cat_trans\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421d224-3cba-4d0c-a4d6-223bc4847c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474524dd-b060-460b-a02a-c0ed31597ddd",
   "metadata": {},
   "source": [
    "> PAMIETAJ - obiekt pipeline to obiekt pythonowy i tak jak obiekt modelu można go zapisać do pickla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe249a-9630-471d-be89-2e56fe311240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,\n",
    "test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae5e9f-f18b-466e-9449-6dcfbf4f9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, 'your_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc7a4a-0d9e-49a9-ac98-b965b7d4f933",
   "metadata": {},
   "source": [
    "TU ZACZYNA SIĘ MAGIA OBIEKTOWEGO PYTHONA - nie pisz kodu i nie uruchamiaj kodów wiele razy dla różnych parametrów - niech Python zrobi to za Ciebie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b3cbd-f118-4793-9e36-d9f6db79dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "              {\"preproc__num_trans__imputer__strategy\":\n",
    "              [\"mean\",\"median\"],\n",
    "               \"model__n_estimators\":[2,5,10,100,500],\n",
    "               \"model__min_samples_leaf\": [1, 0.1],\n",
    "               \"model\":[RandomForestClassifier()]},\n",
    "              {\"preproc__num_trans__imputer__strategy\":\n",
    "                [\"mean\",\"median\"],\n",
    "               \"model__C\":[0.1,1.0,10.0,100.0,1000],\n",
    "                \"model\":[LogisticRegression()]}\n",
    "]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid,\n",
    "cv=2, verbose=1, n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a2f18-0bb0-4157-9c87-50ab47c1e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X_test, y_test), grid_search.score(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d46077-1c83-456e-a981-6c483a93d3a1",
   "metadata": {},
   "source": [
    "Teraz drobna modyfikacja - wiemy, że takiej zmiennej nie chcemy do modelu - ma tylko jedną wartość. \n",
    "Ale jak zweryfikować jakie to zmienne jeśli masz 3 mln kolumn? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83938497-9964-4096-b3e3-6508ddc3999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bad_feature'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84ba5e-c46e-4bfc-bca5-ace37175c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,\n",
    "test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba273a-079e-48fe-bfb7-8498acef10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['math score','reading score','writing score', 'bad_feature']\n",
    "# znajdz sposób na automatyczny podział dla zmiennych numerycznych i nienumerycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6c174-ed96-4a36-822b-b372b4a0bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid,\n",
    "cv=2, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5ed93-ab57-4d5d-be51-8c8e107050b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X_tr, y_tr), grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c5083-927d-45a4-9d85-31d81b2f3afc",
   "metadata": {},
   "source": [
    "### NAPISZ WŁASNĄ KLASĘ KTÓRA ZREALIZUJE TRNSFORMACJE ZA CIEBIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bfbb06-3219-4023-8e7f-15ad9aef1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your own transformator class\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DelOneValueFeature(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Description\"\"\"\n",
    "    def __init__(self):\n",
    "        self.one_value_features = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        for feature in X.columns:\n",
    "            unique = X[feature].unique()\n",
    "            if len(unique)==1:\n",
    "                self.one_value_features.append(feature)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if not self.one_value_features:\n",
    "            return X\n",
    "        return X.drop(axis='columns', columns=self.one_value_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f90630-8cd9-4bf6-98f1-97594df76812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTWÓRZ NOWY PIPELINE\n",
    "pipeline2 = Pipeline([\n",
    "    (\"moja_transformacja\",DelOneValueFeature()),\n",
    "    (\"preprocesser\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression())])\n",
    "    \n",
    "pipeline2.fit(X_tr, y_tr)\n",
    "score2 = pipeline2.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
