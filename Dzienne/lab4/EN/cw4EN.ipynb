{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bae4772-3891-499b-8a1d-5f04fea8c75c",
   "metadata": {},
   "source": [
    "### Unstructured data\n",
    "\n",
    "Unstructured data refers to data that is not organized in any way, such as:\n",
    "\n",
    "- images,\n",
    "- texts,\n",
    "- sounds,\n",
    "- videos.\n",
    "\n",
    "\n",
    "Regardless of the type, we process everything into tensors (multi-dimensional arrays). This may lead to the desire to use ML models and neural networks for analyzing unstructured data.\n",
    "\n",
    "![](data.png)\n",
    "\n",
    "Let's start with images.\n",
    "\n",
    "Create a 2-dim picture with random pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581a868-9b7e-4fd5-b403-e479596539c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_2d = np.random.uniform(size=(28,28))\n",
    "picture_2d[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded90d39-d2ef-4763-a2bc-5b355968a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(picture_2d, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea7c23-43d9-4e8b-9bbe-1298a7d82e20",
   "metadata": {},
   "source": [
    "## What you can do with pictures - PyTorch\n",
    "\n",
    "Load pretrain models for picture classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535ca42-8ddc-4f4f-b43a-2a886a8cd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'https://pytorch.tips/coffee'\n",
    "fpath = 'coffee.jpg'\n",
    "\n",
    "# load picture\n",
    "urllib.request.urlretrieve(url, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e95603-c55d-43d1-8464-9c568f410467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # pillow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78cd6e-84b4-4328-ad4e-b7e272125a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('coffee.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f878df3-bc49-4d3e-b02a-2c5cbbe67a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822984fa-ab9b-4004-94be-59e4421225f9",
   "metadata": {},
   "source": [
    "We will change the properties of the image slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc701e2a-4d40-4ecd-89b1-bd2384e6745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( \n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46484f4-77e6-4ce1-a39f-3cb0f4077d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d95d07-02f1-4cc9-afd4-b19429a4d8a7",
   "metadata": {},
   "source": [
    "Let's consider the shape of our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb64298-13d9-4eaf-ad2c-400b0aba0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(img_tensor), img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33279789-7609-4adb-9f90-365af5cea1dd",
   "metadata": {},
   "source": [
    "Creating batch size - an additional dimension (for other images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2371cd6-3c56-407e-a243-e3ddd53b4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = img_tensor.unsqueeze(0)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "models.list_models()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468c615-dc36-4d01-8c56-92901e23615c",
   "metadata": {},
   "source": [
    "Load alexnet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249295c9-f97b-4758-bf13-f26f1b233b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pleas do not run on laboratories\n",
    "alexnet = models.alexnet(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.eval()\n",
    "predict = alexnet(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5e685-506f-4925-8a76-4ac13c46fd7c",
   "metadata": {},
   "source": [
    "Let's write universal code that you can run on both GPU and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f1d52-10fa-4513-982f-aac0597fa856",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = torch.max(predict,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c6307-5c9d-4009-9b08-55ee620e2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578687b8-444c-4cd2-9f9c-346831eb2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pytorch.tips/imagenet-labels'\n",
    "fpath = 'imagenet_class_labels.txt'\n",
    "urllib.request.urlretrieve(url, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533a1a9-45d9-4ee6-911d-35661e41424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_class_labels.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "classes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da05280-41b1-4dea-a9e7-4d494b03d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(y, dim=1)[0] *100\n",
    "prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[idx.item()], prob[idx.item()].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bdc1ff",
   "metadata": {},
   "source": [
    "Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657235ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "out = resnet(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c636b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(out,1)\n",
    "prob = torch.nn.functional.softmax(out, dim=1)[0] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33afd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[index.item()], prob[index.item()].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5174561-c09b-4e17-92f2-384e40118aab",
   "metadata": {},
   "source": [
    "### More pictures with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60000 obrazow 28x28\n",
    "\n",
    "# Loading the Fashion-MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "# transformacja i normalizacja danych \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0809ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to see some pictures\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.randint(0, images.shape[0], size=25)\n",
    "images_rand = images[indexes]\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = images_rand[i]\n",
    "    plt.imshow(image[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network architecture\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 10),\n",
    "                      nn.LogSoftmax(dim = 1)\n",
    "                     )\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.002)\n",
    "\n",
    "# Define the epochs\n",
    "epochs = 30\n",
    "\n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    \n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model.forward(images)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  else:\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computation\n",
    "    with torch.no_grad():\n",
    "      # Set the model to evaluation mode\n",
    "      model.eval()\n",
    "      \n",
    "      # Validation pass\n",
    "      for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        log_ps = model(images)\n",
    "        test_loss += criterion(log_ps, labels)\n",
    "        \n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    \n",
    "    model.train()\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "    \n",
    "    print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Test loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359e4fa",
   "metadata": {},
   "source": [
    "![](wykres0.png)\n",
    "\n",
    "![](wykres1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label = \"Training loss\")\n",
    "plt.plot(test_losses, label = \"Validation loss\")\n",
    "plt.legend(frameon = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42215e45-a8cf-4e67-b332-4cfdf5ffdcd6",
   "metadata": {},
   "source": [
    "What other networks and layers can we use for analyzing unstructured data?\n",
    "\n",
    "> Find the answer to this question in the Keras library documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My model: \\n\\n\", model, \"\\n\")\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f73b8a-4cc0-400e-b46b-04d27c577ad7",
   "metadata": {},
   "source": [
    "## Text data and BoW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46dc96e-85de-4bea-b5d8-9f9cdb53e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train = df_train.drop(\"index\", axis=1)\n",
    "print(df_train.head())\n",
    "print(np.bincount(df_train[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099c2fb-30de-4c01-b924-2d3a3f09a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW model \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(lowercase=True, max_features=10_000, stop_words=\"english\")\n",
    "\n",
    "cv.fit(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a156b7-80c4-41ba-bde2-4f684dda7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary.\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b1c4-9a7a-4653-acdb-4282b139843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.transform(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0adf4-ad47-4913-9b7e-b41b3093a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to dense matrix\n",
    "feat_vec = np.array(X_train[0].todense())[0]\n",
    "print(feat_vec.shape)\n",
    "np.bincount(feat_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9329ba9a-94bb-488c-a8b8-83c8b9de7af8",
   "metadata": {},
   "source": [
    "## OOP for modeling in state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a19144-7545-49cc-b534-919cbdbb8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# data example\n",
    "df = pd.read_csv(\"students.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e031a3-10e7-4c3e-921a-400d786277b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dc43d-cfae-4cac-932e-6e514dc8c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa64470-983b-49e2-892b-3a0e6eb08e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# FIRST prepare pipeline\n",
    "\n",
    "numeric_features = ['math score','reading score','writing score']\n",
    "categorical_features = ['sex','race/ethnicity','parental level of education','lunch','test preparation course']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c8b94-0719-49cc-9c47-b7d0fbb55907",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0ec3a-bf9d-4760-b01b-7bea1734de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_trans\", numeric_transformer, numeric_features),\n",
    "    (\"cat_trans\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421d224-3cba-4d0c-a4d6-223bc4847c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474524dd-b060-460b-a02a-c0ed31597ddd",
   "metadata": {},
   "source": [
    "> Just remember - pipeline object is a python object. So you can save it as ordinary pickle object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe249a-9630-471d-be89-2e56fe311240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,\n",
    "test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae5e9f-f18b-466e-9449-6dcfbf4f9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, 'your_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc7a4a-0d9e-49a9-ac98-b965b7d4f933",
   "metadata": {},
   "source": [
    "Now the magic start's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b3cbd-f118-4793-9e36-d9f6db79dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "              {\"preproc__num_trans__imputer__strategy\":\n",
    "              [\"mean\",\"median\"],\n",
    "               \"model__n_estimators\":[2,5,10,100,500],\n",
    "               \"model__min_samples_leaf\": [1, 0.1],\n",
    "               \"model\":[RandomForestClassifier()]},\n",
    "              {\"preproc__num_trans__imputer__strategy\":\n",
    "                [\"mean\",\"median\"],\n",
    "               \"model__C\":[0.1,1.0,10.0,100.0,1000],\n",
    "                \"model\":[LogisticRegression()]}\n",
    "]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid,\n",
    "cv=2, verbose=1, n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a2f18-0bb0-4157-9c87-50ab47c1e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X_test, y_test), grid_search.score(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83938497-9964-4096-b3e3-6508ddc3999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bad_feature'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84ba5e-c46e-4bfc-bca5-ace37175c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,\n",
    "test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba273a-079e-48fe-bfb7-8498acef10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['math score','reading score','writing score', 'bad_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6c174-ed96-4a36-822b-b372b4a0bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid,\n",
    "cv=2, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5ed93-ab57-4d5d-be51-8c8e107050b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X_tr, y_tr), grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c5083-927d-45a4-9d85-31d81b2f3afc",
   "metadata": {},
   "source": [
    "### Write your transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bfbb06-3219-4023-8e7f-15ad9aef1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your own transformator class\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DelOneValueFeature(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Description\"\"\"\n",
    "    def __init__(self):\n",
    "        self.one_value_features = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        for feature in X.columns:\n",
    "            unique = X[feature].unique()\n",
    "            if len(unique)==1:\n",
    "                self.one_value_features.append(feature)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if not self.one_value_features:\n",
    "            return X\n",
    "        return X.drop(axis='columns', columns=self.one_value_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f90630-8cd9-4bf6-98f1-97594df76812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New pipeline\n",
    "pipeline2 = Pipeline([\n",
    "    (\"moja_transformacja\",DelOneValueFeature()),\n",
    "    (\"preprocesser\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression())])\n",
    "    \n",
    "pipeline2.fit(X_tr, y_tr)\n",
    "score2 = pipeline2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4bdd7-1bc8-4a20-973a-d785cc4b38f6",
   "metadata": {},
   "source": [
    "Thats all! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663b985-42cb-47fa-a5c5-6ec6741043c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstructured data\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b8212-96c9-4146-b1b7-9a8115521292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') > 0.95:\n",
    "            print(\"\\n You get 95% acc - finish\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5fafc-d67c-43eb-9cf1-72b002fab744",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3022dae-2cc9-4c94-b459-58550b42fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tr_im, tr_lab),(te_im, te_lab) = mnist.load_data()\n",
    "tr_im = tr_im/255\n",
    "te_im = te_im/255\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b950c7-76b4-4327-8fb4-d333e5efa022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tr_im, tr_lab, epochs=40, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce55c1-9b3a-4296-a2a2-5dd4364f7bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
